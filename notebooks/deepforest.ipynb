{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = raw_data.drop([\"Cabin\", \"Name\", \"PassengerId\", \"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data = pd.get_dummies(clean_data).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_x_y(dataframe, target):\n",
    "    return dataframe.drop(target, axis=1), dataframe[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = split_x_y(train, \"Survived\")\n",
    "X_test, y_test = split_x_y(test, \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424081632653061"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=4)\n",
    "rf2 = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf1.fit(X_train, y_train)\n",
    "y_pred_train_1 = rf1.predict_proba(X_train)\n",
    "y_pred_test_1 = rf1.predict_proba(X_test)\n",
    "\n",
    "y_pred_train_1 = pd.DataFrame(y_pred_train_1, columns=[\"rf1_0\", \"rf1_1\"], index=X_train.index)\n",
    "y_pred_test_1 = pd.DataFrame(y_pred_test_1, columns=[\"rf1_0\", \"rf1_1\"], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf2.fit(X_train, y_train)\n",
    "y_pred_train_2 = rf2.predict_proba(X_train)\n",
    "y_pred_test_2 = rf2.predict_proba(X_test)\n",
    "\n",
    "y_pred_train_2 = pd.DataFrame(y_pred_train_2, columns=[\"rf2_0\", \"rf2_1\"], index=X_train.index)\n",
    "y_pred_test_2 = pd.DataFrame(y_pred_test_2, columns=[\"rf2_0\", \"rf2_1\"], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_train_1 = pd.concat([X_train, y_pred_train_1, y_pred_train_2], axis=1)\n",
    "hidden_test_1 = pd.concat([X_test, y_pred_test_1, y_pred_test_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>rf1_0</th>\n",
       "      <th>rf1_1</th>\n",
       "      <th>rf2_0</th>\n",
       "      <th>rf2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.626112</td>\n",
       "      <td>0.373888</td>\n",
       "      <td>0.755285</td>\n",
       "      <td>0.244715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.802091</td>\n",
       "      <td>0.197909</td>\n",
       "      <td>0.887265</td>\n",
       "      <td>0.112735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650493</td>\n",
       "      <td>0.349507</td>\n",
       "      <td>0.435268</td>\n",
       "      <td>0.564732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889424</td>\n",
       "      <td>0.110576</td>\n",
       "      <td>0.972478</td>\n",
       "      <td>0.027522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch      Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "493       1  71.0      0      0   49.5042           0         1           1   \n",
       "779       1  43.0      0      1  211.3375           1         0           0   \n",
       "153       3  40.5      0      2   14.5000           0         1           0   \n",
       "621       1  42.0      1      0   52.5542           0         1           0   \n",
       "234       2  24.0      0      0   10.5000           0         1           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S     rf1_0     rf1_1     rf2_0     rf2_1  \n",
       "493           0           0  0.626112  0.373888  0.755285  0.244715  \n",
       "779           0           1  0.097917  0.902083  0.000000  1.000000  \n",
       "153           0           1  0.802091  0.197909  0.887265  0.112735  \n",
       "621           0           1  0.650493  0.349507  0.435268  0.564732  \n",
       "234           0           1  0.889424  0.110576  0.972478  0.027522  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "rf3.fit(hidden_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred3 = rf3.predict_proba(hidden_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84199999999999997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred3[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepforest.layer import Layer, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = InputLayer(RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=4),\n",
    "                         RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer = Layer(input_layer,\n",
    "                     RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=4),\n",
    "                     RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepforest.layer.Layer at 0x1082a0240>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model0_0</th>\n",
       "      <th>model0_1</th>\n",
       "      <th>model1_0</th>\n",
       "      <th>model1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.904868</td>\n",
       "      <td>0.095132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.904868</td>\n",
       "      <td>0.095132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.981422</td>\n",
       "      <td>0.018578</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.984167</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.987143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.974776</td>\n",
       "      <td>0.025224</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.990357</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.984212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.998404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.969267</td>\n",
       "      <td>0.030733</td>\n",
       "      <td>0.952589</td>\n",
       "      <td>0.047411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.163292</td>\n",
       "      <td>0.836708</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.990668</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.086230</td>\n",
       "      <td>0.913770</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.991509</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.985972</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.980092</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.998383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.007922</td>\n",
       "      <td>0.992078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.067324</td>\n",
       "      <td>0.932676</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.991429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.018629</td>\n",
       "      <td>0.981371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.984593</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.996259</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.995497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.923957</td>\n",
       "      <td>0.076043</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.985688</td>\n",
       "      <td>0.014312</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.979103</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.998632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.280945</td>\n",
       "      <td>0.719055</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.989017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.991433</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.124302</td>\n",
       "      <td>0.875698</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.988726</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.275235</td>\n",
       "      <td>0.724765</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.147052</td>\n",
       "      <td>0.852948</td>\n",
       "      <td>0.182063</td>\n",
       "      <td>0.817937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.997775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.991921</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.975602</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.033684</td>\n",
       "      <td>0.966316</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.971333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.997775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.884067</td>\n",
       "      <td>0.115933</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.253333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.990083</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.984514</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.995842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0.977784</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.904969</td>\n",
       "      <td>0.095031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.025335</td>\n",
       "      <td>0.974665</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0.950667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.995154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.990083</td>\n",
       "      <td>0.009917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.947100</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.091667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0.060996</td>\n",
       "      <td>0.939004</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.974667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.134948</td>\n",
       "      <td>0.865052</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.995147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.970079</td>\n",
       "      <td>0.029921</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.984593</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.974474</td>\n",
       "      <td>0.025526</td>\n",
       "      <td>0.883884</td>\n",
       "      <td>0.116116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.128387</td>\n",
       "      <td>0.871613</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model0_0  model0_1  model1_0  model1_1\n",
       "741  0.904868  0.095132  1.000000  0.000000\n",
       "224  0.904868  0.095132  1.000000  0.000000\n",
       "313  0.981422  0.018578  0.997500  0.002500\n",
       "254  0.015833  0.984167  0.012857  0.987143\n",
       "188  0.974776  0.025224  0.977500  0.022500\n",
       "154  0.990357  0.009643  0.999545  0.000455\n",
       "140  0.015788  0.984212  0.000000  1.000000\n",
       "316  0.001596  0.998404  0.000000  1.000000\n",
       "552  0.969267  0.030733  0.952589  0.047411\n",
       "60   0.163292  0.836708  0.032000  0.968000\n",
       "69   0.990668  0.009332  1.000000  0.000000\n",
       "882  0.086230  0.913770  0.040000  0.960000\n",
       "846  0.991509  0.008491  1.000000  0.000000\n",
       "421  0.985972  0.014028  0.999545  0.000455\n",
       "309  0.004158  0.995842  0.000000  1.000000\n",
       "144  0.980092  0.019908  1.000000  0.000000\n",
       "473  0.001617  0.998383  0.000000  1.000000\n",
       "166  0.007922  0.992078  0.000000  1.000000\n",
       "34   0.067324  0.932676  0.040000  0.960000\n",
       "15   0.001670  0.998330  0.008571  0.991429\n",
       "319  0.000263  0.999737  0.000000  1.000000\n",
       "56   0.018629  0.981371  0.000000  1.000000\n",
       "773  0.984593  0.015407  1.000000  0.000000\n",
       "195  0.004158  0.995842  0.020000  0.980000\n",
       "513  0.003741  0.996259  0.020000  0.980000\n",
       "257  0.004503  0.995497  0.000000  1.000000\n",
       "289  0.923957  0.076043  0.960000  0.040000\n",
       "365  0.985688  0.014312  0.999545  0.000455\n",
       "510  0.979103  0.020897  0.999545  0.000455\n",
       "853  0.001368  0.998632  0.000000  1.000000\n",
       "..        ...       ...       ...       ...\n",
       "83   0.280945  0.719055  0.280000  0.720000\n",
       "334  0.010983  0.989017  0.000000  1.000000\n",
       "199  0.001962  0.998038  0.000000  1.000000\n",
       "596  0.008567  0.991433  0.040000  0.960000\n",
       "503  0.124302  0.875698  0.060000  0.940000\n",
       "836  0.988726  0.011274  1.000000  0.000000\n",
       "377  0.275235  0.724765  0.310000  0.690000\n",
       "300  0.147052  0.852948  0.182063  0.817937\n",
       "706  0.002225  0.997775  0.000000  1.000000\n",
       "278  0.991921  0.008079  1.000000  0.000000\n",
       "116  0.975602  0.024398  0.999545  0.000455\n",
       "358  0.033684  0.966316  0.028667  0.971333\n",
       "190  0.002225  0.997775  0.000000  1.000000\n",
       "668  0.884067  0.115933  0.746667  0.253333\n",
       "29   0.990083  0.009917  1.000000  0.000000\n",
       "391  0.984514  0.015486  1.000000  0.000000\n",
       "218  0.004158  0.995842  0.000000  1.000000\n",
       "586  0.977784  0.022216  1.000000  0.000000\n",
       "62   0.904969  0.095031  1.000000  0.000000\n",
       "128  0.025335  0.974665  0.049333  0.950667\n",
       "627  0.004846  0.995154  0.000000  1.000000\n",
       "667  0.990083  0.009917  1.000000  0.000000\n",
       "122  0.947100  0.052900  0.908333  0.091667\n",
       "727  0.060996  0.939004  0.025333  0.974667\n",
       "321  0.134948  0.865052  0.004853  0.995147\n",
       "124  0.970079  0.029921  0.980000  0.020000\n",
       "581  0.000263  0.999737  0.000000  1.000000\n",
       "568  0.984593  0.015407  1.000000  0.000000\n",
       "613  0.974474  0.025526  0.883884  0.116116\n",
       "270  0.128387  0.871613  0.020000  0.980000\n",
       "\n",
       "[223 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# On teste plus loin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_generator():\n",
    "    for i in range(2, 15, 2):\n",
    "        yield RandomForestClassifier(n_estimators=100,\n",
    "                                     n_jobs=-1,\n",
    "                                     min_samples_leaf=5,\n",
    "                                     max_depth=i)\n",
    "    for i in range(2, 15, 2):\n",
    "        yield RandomForestClassifier(n_estimators=100,\n",
    "                                     n_jobs=-1,\n",
    "                                     max_features=1,\n",
    "                                     min_samples_leaf=5,\n",
    "                                     max_depth=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_layer():\n",
    "    return InputLayer(*random_forest_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer(layer):\n",
    "    return Layer(layer, *random_forest_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_layer(layer):\n",
    "    return Layer(layer,\n",
    "                 RandomForestClassifier(n_estimators=500,\n",
    "                                        n_jobs=-1,\n",
    "                                        min_samples_leaf=5,\n",
    "                                        max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_l = input_layer()\n",
    "hidden_1 = hidden_layer(input_l)\n",
    "hidden_2 = hidden_layer(hidden_1)\n",
    "hidden_3 = hidden_layer(hidden_2)\n",
    "hidden_4 = hidden_layer(hidden_3)\n",
    "output_l = output_layer(hidden_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepforest.layer.Layer at 0x112740e48>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_l.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = output_l.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81224489795918364"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
