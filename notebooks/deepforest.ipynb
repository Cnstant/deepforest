{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data from kaggle first :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(pkg_resources.resource_stream('deepforest', 'data/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data = raw_data.drop([\"Cabin\", \"Name\", \"PassengerId\", \"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data = pd.get_dummies(clean_data).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_x_y(dataframe, target):\n",
    "    return dataframe.drop(target, axis=1), dataframe[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = split_x_y(train, \"Survived\")\n",
    "X_test, y_test = split_x_y(test, \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_true=y_test, y_score=y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86788399570354469"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=4)\n",
    "rf2 = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf1.fit(X_train, y_train)\n",
    "y_pred_train_1 = rf1.predict_proba(X_train)\n",
    "y_pred_test_1 = rf1.predict_proba(X_test)\n",
    "\n",
    "y_pred_train_1 = pd.DataFrame(y_pred_train_1, columns=[\"rf1_0\", \"rf1_1\"], index=X_train.index)\n",
    "y_pred_test_1 = pd.DataFrame(y_pred_test_1, columns=[\"rf1_0\", \"rf1_1\"], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf2.fit(X_train, y_train)\n",
    "y_pred_train_2 = rf2.predict_proba(X_train)\n",
    "y_pred_test_2 = rf2.predict_proba(X_test)\n",
    "\n",
    "y_pred_train_2 = pd.DataFrame(y_pred_train_2, columns=[\"rf2_0\", \"rf2_1\"], index=X_train.index)\n",
    "y_pred_test_2 = pd.DataFrame(y_pred_test_2, columns=[\"rf2_0\", \"rf2_1\"], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_train_1 = pd.concat([X_train, y_pred_train_1, y_pred_train_2], axis=1)\n",
    "hidden_test_1 = pd.concat([X_test, y_pred_test_1, y_pred_test_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>rf1_0</th>\n",
       "      <th>rf1_1</th>\n",
       "      <th>rf2_0</th>\n",
       "      <th>rf2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.410273</td>\n",
       "      <td>0.589727</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.743256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070023</td>\n",
       "      <td>0.929977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863169</td>\n",
       "      <td>0.136831</td>\n",
       "      <td>0.938984</td>\n",
       "      <td>0.061016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890193</td>\n",
       "      <td>0.109807</td>\n",
       "      <td>0.931481</td>\n",
       "      <td>0.068519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087613</td>\n",
       "      <td>0.912387</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  SibSp  Parch      Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "786       3  18.0      0      0    7.4958           1         0           0   \n",
       "627       1  21.0      0      0   77.9583           1         0           0   \n",
       "695       2  52.0      0      0   13.5000           0         1           0   \n",
       "379       3  19.0      0      0    7.7750           0         1           0   \n",
       "708       1  22.0      0      0  151.5500           1         0           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S     rf1_0     rf1_1     rf2_0     rf2_1  \n",
       "786           0           1  0.410273  0.589727  0.256744  0.743256  \n",
       "627           0           1  0.070023  0.929977  0.000000  1.000000  \n",
       "695           0           1  0.863169  0.136831  0.938984  0.061016  \n",
       "379           0           1  0.890193  0.109807  0.931481  0.068519  \n",
       "708           0           1  0.087613  0.912387  0.030000  0.970000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "rf3.fit(hidden_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred3 = rf3.predict_proba(hidden_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86040995345506621"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred3[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not very handy, not at all. We already see a lot of code duplication, and one may feel there may be a way to abstract a lot of the logic that is happening here, in a way that is more flexible and powerful that all this boilerplate code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deepforest.layer import Layer, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer = InputLayer(RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=4),\n",
    "                         RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_layer = Layer(input_layer,\n",
    "                     RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=4),\n",
    "                     RandomForestClassifier(n_estimators=50, n_jobs=-1, max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepforest.layer.Layer at 0x104522d30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.886403</td>\n",
       "      <td>0.113597</td>\n",
       "      <td>0.840710</td>\n",
       "      <td>0.159290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.176103</td>\n",
       "      <td>0.823897</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.929972</td>\n",
       "      <td>0.070028</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.970997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.892927</td>\n",
       "      <td>0.107073</td>\n",
       "      <td>0.921950</td>\n",
       "      <td>0.078050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.902629</td>\n",
       "      <td>0.097371</td>\n",
       "      <td>0.755414</td>\n",
       "      <td>0.244586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.893365</td>\n",
       "      <td>0.106635</td>\n",
       "      <td>0.892192</td>\n",
       "      <td>0.107808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.876441</td>\n",
       "      <td>0.123559</td>\n",
       "      <td>0.781518</td>\n",
       "      <td>0.218482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.890743</td>\n",
       "      <td>0.109257</td>\n",
       "      <td>0.918327</td>\n",
       "      <td>0.081673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.909326</td>\n",
       "      <td>0.090674</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.063333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.907381</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.971794</td>\n",
       "      <td>0.028206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.923719</td>\n",
       "      <td>0.076281</td>\n",
       "      <td>0.977759</td>\n",
       "      <td>0.022241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.130872</td>\n",
       "      <td>0.869128</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.995962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0.911772</td>\n",
       "      <td>0.088228</td>\n",
       "      <td>0.978350</td>\n",
       "      <td>0.021650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.918126</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>0.883977</td>\n",
       "      <td>0.116023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.161277</td>\n",
       "      <td>0.838723</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.978857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.094557</td>\n",
       "      <td>0.905443</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.893387</td>\n",
       "      <td>0.106613</td>\n",
       "      <td>0.936368</td>\n",
       "      <td>0.063632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0.885771</td>\n",
       "      <td>0.114229</td>\n",
       "      <td>0.968222</td>\n",
       "      <td>0.031778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.891792</td>\n",
       "      <td>0.108208</td>\n",
       "      <td>0.922608</td>\n",
       "      <td>0.077392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0.028675</td>\n",
       "      <td>0.971325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.843012</td>\n",
       "      <td>0.156988</td>\n",
       "      <td>0.957742</td>\n",
       "      <td>0.042258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.747858</td>\n",
       "      <td>0.252142</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.871790</td>\n",
       "      <td>0.128210</td>\n",
       "      <td>0.955844</td>\n",
       "      <td>0.044156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.882282</td>\n",
       "      <td>0.117718</td>\n",
       "      <td>0.878046</td>\n",
       "      <td>0.121954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.050097</td>\n",
       "      <td>0.949903</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.998857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.891427</td>\n",
       "      <td>0.108573</td>\n",
       "      <td>0.886614</td>\n",
       "      <td>0.113386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0.911842</td>\n",
       "      <td>0.088158</td>\n",
       "      <td>0.848512</td>\n",
       "      <td>0.151488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>0.117489</td>\n",
       "      <td>0.882511</td>\n",
       "      <td>0.079613</td>\n",
       "      <td>0.920387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.932624</td>\n",
       "      <td>0.067376</td>\n",
       "      <td>0.997895</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.725637</td>\n",
       "      <td>0.274363</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.011429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.899280</td>\n",
       "      <td>0.100720</td>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.042269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.099159</td>\n",
       "      <td>0.900841</td>\n",
       "      <td>0.035139</td>\n",
       "      <td>0.964861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0.890895</td>\n",
       "      <td>0.109105</td>\n",
       "      <td>0.992737</td>\n",
       "      <td>0.007263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.895626</td>\n",
       "      <td>0.104374</td>\n",
       "      <td>0.944614</td>\n",
       "      <td>0.055386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.885562</td>\n",
       "      <td>0.114438</td>\n",
       "      <td>0.977491</td>\n",
       "      <td>0.022509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.897268</td>\n",
       "      <td>0.102732</td>\n",
       "      <td>0.954851</td>\n",
       "      <td>0.045149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.893387</td>\n",
       "      <td>0.106613</td>\n",
       "      <td>0.936368</td>\n",
       "      <td>0.063632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.858684</td>\n",
       "      <td>0.141316</td>\n",
       "      <td>0.903854</td>\n",
       "      <td>0.096146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.157551</td>\n",
       "      <td>0.842449</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.915763</td>\n",
       "      <td>0.084237</td>\n",
       "      <td>0.978374</td>\n",
       "      <td>0.021626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.900999</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.943801</td>\n",
       "      <td>0.056199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.889687</td>\n",
       "      <td>0.110313</td>\n",
       "      <td>0.912508</td>\n",
       "      <td>0.087492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.908515</td>\n",
       "      <td>0.091485</td>\n",
       "      <td>0.958836</td>\n",
       "      <td>0.041164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.907381</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.980683</td>\n",
       "      <td>0.019317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.913077</td>\n",
       "      <td>0.086923</td>\n",
       "      <td>0.925646</td>\n",
       "      <td>0.074354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.906358</td>\n",
       "      <td>0.093642</td>\n",
       "      <td>0.954353</td>\n",
       "      <td>0.045647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.874089</td>\n",
       "      <td>0.125911</td>\n",
       "      <td>0.895357</td>\n",
       "      <td>0.104643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0.727689</td>\n",
       "      <td>0.272311</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.743507</td>\n",
       "      <td>0.256493</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.116100</td>\n",
       "      <td>0.883900</td>\n",
       "      <td>0.519613</td>\n",
       "      <td>0.480387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.879062</td>\n",
       "      <td>0.120938</td>\n",
       "      <td>0.894773</td>\n",
       "      <td>0.105227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.918126</td>\n",
       "      <td>0.081874</td>\n",
       "      <td>0.883977</td>\n",
       "      <td>0.116023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.877184</td>\n",
       "      <td>0.122816</td>\n",
       "      <td>0.981473</td>\n",
       "      <td>0.018527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.147430</td>\n",
       "      <td>0.852570</td>\n",
       "      <td>0.147257</td>\n",
       "      <td>0.852743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.180075</td>\n",
       "      <td>0.819925</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.112588</td>\n",
       "      <td>0.887412</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.044899</td>\n",
       "      <td>0.955101</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.927508</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.911442</td>\n",
       "      <td>0.088558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.901662</td>\n",
       "      <td>0.098338</td>\n",
       "      <td>0.977701</td>\n",
       "      <td>0.022299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3\n",
       "81   0.886403  0.113597  0.840710  0.159290\n",
       "889  0.176103  0.823897  0.020000  0.980000\n",
       "188  0.929972  0.070028  0.993103  0.006897\n",
       "742  0.029003  0.970997  0.000000  1.000000\n",
       "146  0.892927  0.107073  0.921950  0.078050\n",
       "99   0.902629  0.097371  0.755414  0.244586\n",
       "197  0.893365  0.106635  0.892192  0.107808\n",
       "814  0.876441  0.123559  0.781518  0.218482\n",
       "836  0.890743  0.109257  0.918327  0.081673\n",
       "13   0.909326  0.090674  0.936667  0.063333\n",
       "465  0.907381  0.092619  0.971794  0.028206\n",
       "860  0.923719  0.076281  0.977759  0.022241\n",
       "156  0.130872  0.869128  0.004038  0.995962\n",
       "674  0.911772  0.088228  0.978350  0.021650\n",
       "790  0.918126  0.081874  0.883977  0.116023\n",
       "567  0.161277  0.838723  0.021143  0.978857\n",
       "133  0.094557  0.905443  0.006000  0.994000\n",
       "709  0.893387  0.106613  0.936368  0.063632\n",
       "843  0.885771  0.114229  0.968222  0.031778\n",
       "734  0.891792  0.108208  0.922608  0.077392\n",
       "537  0.028675  0.971325  0.000000  1.000000\n",
       "92   0.843012  0.156988  0.957742  0.042258\n",
       "729  0.747858  0.252142  0.976667  0.023333\n",
       "694  0.871790  0.128210  0.955844  0.044156\n",
       "89   0.882282  0.117718  0.878046  0.121954\n",
       "269  0.050097  0.949903  0.001143  0.998857\n",
       "606  0.891427  0.108573  0.886614  0.113386\n",
       "552  0.911842  0.088158  0.848512  0.151488\n",
       "576  0.117489  0.882511  0.079613  0.920387\n",
       "386  0.932624  0.067376  0.997895  0.002105\n",
       "..        ...       ...       ...       ...\n",
       "49   0.725637  0.274363  0.988571  0.011429\n",
       "384  0.899280  0.100720  0.957731  0.042269\n",
       "303  0.099159  0.900841  0.035139  0.964861\n",
       "839  0.890895  0.109105  0.992737  0.007263\n",
       "162  0.895626  0.104374  0.944614  0.055386\n",
       "492  0.885562  0.114438  0.977491  0.022509\n",
       "753  0.897268  0.102732  0.954851  0.045149\n",
       "65   0.893387  0.106613  0.936368  0.063632\n",
       "72   0.858684  0.141316  0.903854  0.096146\n",
       "755  0.157551  0.842449  0.004000  0.996000\n",
       "749  0.915763  0.084237  0.978374  0.021626\n",
       "69   0.900999  0.099001  0.943801  0.056199\n",
       "221  0.889687  0.110313  0.912508  0.087492\n",
       "267  0.908515  0.091485  0.958836  0.041164\n",
       "590  0.907381  0.092619  0.980683  0.019317\n",
       "175  0.913077  0.086923  0.925646  0.074354\n",
       "704  0.906358  0.093642  0.954353  0.045647\n",
       "292  0.874089  0.125911  0.895357  0.104643\n",
       "888  0.727689  0.272311  0.940000  0.060000\n",
       "2    0.743507  0.256493  0.980000  0.020000\n",
       "346  0.116100  0.883900  0.519613  0.480387\n",
       "95   0.879062  0.120938  0.894773  0.105227\n",
       "260  0.918126  0.081874  0.883977  0.116023\n",
       "475  0.877184  0.122816  0.981473  0.018527\n",
       "47   0.147430  0.852570  0.147257  0.852743\n",
       "599  0.180075  0.819925  0.020000  0.980000\n",
       "644  0.112588  0.887412  0.040000  0.960000\n",
       "166  0.044899  0.955101  0.008000  0.992000\n",
       "214  0.927508  0.072492  0.911442  0.088558\n",
       "622  0.901662  0.098338  0.977701  0.022299\n",
       "\n",
       "[223 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hidden_layer.predict(X_test), index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Going Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_generator():\n",
    "    for i in range(2, 15, 2):\n",
    "        yield RandomForestClassifier(n_estimators=100,\n",
    "                                     n_jobs=-1,\n",
    "                                     min_samples_leaf=5,\n",
    "                                     max_depth=i)\n",
    "    for i in range(2, 15, 2):\n",
    "        yield RandomForestClassifier(n_estimators=100,\n",
    "                                     n_jobs=-1,\n",
    "                                     max_features=1,\n",
    "                                     min_samples_leaf=5,\n",
    "                                     max_depth=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paper_like_generator():\n",
    "    for i in range(2):\n",
    "        yield RandomForestClassifier(n_estimators=1000,\n",
    "                                     n_jobs=-1,\n",
    "                                     min_samples_leaf=10)\n",
    "    for i in range(2):\n",
    "        yield RandomForestClassifier(n_estimators=1000,\n",
    "                                     n_jobs=-1,\n",
    "                                     max_features=1,\n",
    "                                     min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_input_layer():\n",
    "    return InputLayer(*paper_like_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_hidden_layer(layer):\n",
    "    return Layer(layer, *paper_like_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output_layer(layer):\n",
    "    return Layer(layer,\n",
    "                 RandomForestClassifier(n_estimators=500,\n",
    "                                        n_jobs=-1,\n",
    "                                        min_samples_leaf=5,\n",
    "                                        max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_l = build_input_layer()\n",
    "hidden_1 = build_hidden_layer(input_l)\n",
    "hidden_2 = build_hidden_layer(hidden_1)\n",
    "hidden_3 = build_hidden_layer(hidden_2)\n",
    "hidden_4 = build_hidden_layer(hidden_3)\n",
    "output_l = build_output_layer(hidden_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepforest.layer.Layer at 0x104512978>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_l.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = output_l.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.29638699e-01,   7.03613014e-02],\n",
       "       [  1.72212883e-01,   8.27787117e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.27478992e-03,   9.92725210e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.52790052e-01,   2.47209948e-01],\n",
       "       [  9.59129256e-01,   4.08707444e-02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  3.09158979e-01,   6.90841021e-01],\n",
       "       [  9.97466667e-01,   2.53333333e-03],\n",
       "       [  8.88917085e-01,   1.11082915e-01],\n",
       "       [  3.52073705e-01,   6.47926295e-01],\n",
       "       [  3.72293325e-01,   6.27706675e-01],\n",
       "       [  2.88891001e-01,   7.11108999e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.42849243e-01,   8.57150757e-01],\n",
       "       [  9.94265995e-01,   5.73400488e-03],\n",
       "       [  5.31304247e-01,   4.68695753e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  7.79309549e-01,   2.20690451e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  9.97466667e-01,   2.53333333e-03],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  2.85085104e-01,   7.14914896e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  9.76749260e-01,   2.32507404e-02],\n",
       "       [  9.97733117e-01,   2.26688312e-03],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e-03,   9.99000000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  4.18106720e-01,   5.81893280e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  3.68057044e-01,   6.31942956e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.43477107e-01,   2.56522893e-01],\n",
       "       [  1.00000000e-03,   9.99000000e-01],\n",
       "       [  3.33333333e-04,   9.99666667e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  5.89930916e-01,   4.10069084e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  8.00000000e-04,   9.99200000e-01],\n",
       "       [  2.75012123e-01,   7.24987877e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  4.21895897e-01,   5.78104103e-01],\n",
       "       [  9.97238528e-01,   2.76147186e-03],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  9.60791699e-01,   3.92083007e-02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  6.05880231e-03,   9.93941198e-01],\n",
       "       [  6.03921085e-02,   9.39607891e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  9.57124841e-01,   4.28751587e-02],\n",
       "       [  9.37848142e-02,   9.06215186e-01],\n",
       "       [  1.05903796e-02,   9.89409620e-01],\n",
       "       [  9.71861676e-01,   2.81383244e-02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  3.72293325e-01,   6.27706675e-01],\n",
       "       [  1.00121662e-01,   8.99878338e-01],\n",
       "       [  1.48621515e-01,   8.51378485e-01],\n",
       "       [  8.75704622e-03,   9.91242954e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.89456509e-01,   8.10543491e-01],\n",
       "       [  9.99666667e-01,   3.33333333e-04],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  3.47143943e-01,   6.52856057e-01],\n",
       "       [  9.30603195e-01,   6.93968050e-02],\n",
       "       [  8.50221529e-01,   1.49778471e-01],\n",
       "       [  6.38185437e-01,   3.61814563e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.05779498e-01,   2.94220502e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  9.92754884e-01,   7.24511600e-03],\n",
       "       [  9.57180501e-04,   9.99042819e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  4.20217831e-01,   5.79782169e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.42777254e-01,   8.57222746e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.46889453e-01,   8.53110547e-01],\n",
       "       [  9.98304545e-01,   1.69545455e-03],\n",
       "       [  7.53396290e-01,   2.46603710e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  6.96086107e-01,   3.03913893e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.35718050e-03,   9.98642819e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  3.19960474e-03,   9.96800395e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.87874913e-03,   9.98121251e-01],\n",
       "       [  5.07416827e-02,   9.49258317e-01],\n",
       "       [  9.79580854e-01,   2.04191457e-02],\n",
       "       [  9.99666667e-01,   3.33333333e-04],\n",
       "       [  5.00000000e-04,   9.99500000e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  6.52558301e-01,   3.47441699e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  9.57180501e-04,   9.99042819e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  3.48450710e-01,   6.51549290e-01],\n",
       "       [  8.74391634e-02,   9.12560837e-01],\n",
       "       [  3.33333333e-04,   9.99666667e-01],\n",
       "       [  7.78466518e-01,   2.21533482e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  2.97478992e-03,   9.97025210e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  9.97466667e-01,   2.53333333e-03],\n",
       "       [  1.05016455e-01,   8.94983545e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.80700119e-01,   2.19299881e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  3.68494014e-01,   6.31505986e-01],\n",
       "       [  9.99142857e-01,   8.57142857e-04],\n",
       "       [  9.99682353e-01,   3.17647059e-04],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.39823314e-03,   9.98601767e-01],\n",
       "       [  3.33333333e-04,   9.99666667e-01],\n",
       "       [  1.25000000e-03,   9.98750000e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  6.48604955e-01,   3.51395045e-01],\n",
       "       [  9.69221691e-01,   3.07783094e-02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  5.38431373e-03,   9.94615686e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  8.13453221e-01,   1.86546779e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  8.00000000e-04,   9.99200000e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  9.29638699e-01,   7.03613014e-02],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  5.20721759e-01,   4.79278241e-01],\n",
       "       [  8.88917085e-01,   1.11082915e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  4.24548278e-01,   5.75451722e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  7.90513834e-04,   9.99209486e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  2.88891001e-01,   7.11108999e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  4.00000000e-04,   9.99600000e-01],\n",
       "       [  9.99666667e-01,   3.33333333e-04],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  5.99625042e-01,   4.00374958e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  9.99666667e-01,   3.33333333e-04],\n",
       "       [  9.43014139e-02,   9.05698586e-01],\n",
       "       [  3.91634773e-01,   6.08365227e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  8.88917085e-01,   1.11082915e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00],\n",
       "       [  1.61653007e-01,   8.38346993e-01],\n",
       "       [  9.23118030e-01,   7.68819699e-02],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  9.99666667e-01,   3.33333333e-04],\n",
       "       [  9.96500000e-01,   3.50000000e-03]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81846846846846855"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Well the result is not that satisfactory yet, but let's not loose hope. There is a lot of room for improvement yet. First item on my todo list: make sure all the intermediary models are trained using cross-validation techniques, to reduce overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
